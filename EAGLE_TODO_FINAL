# TurboMind EAGLE3 – Final TODO Snapshot (Code State as of Current Branch)

This file reflects the **current implementation** in this repo and the
**remaining coding work** needed to get as close as practical to
TensorRT‑LLM Eagle‑3 behaviour on TurboMind.

It is implementation‑only: no process, no docs, no tests.

Status markers:
- `[x]` implemented in this tree (may still need tuning)
- `[ ]` not implemented / still to do

---

## 0. High‑Level Progress (per area)

- Target‑tree decode (TurboMind target side):
  - **[x]** Prepared tree inputs (`targetTreeDecode` → `EagleBuffers::inputs.eagle_net_*`).
  - **[x]** Scratch KV tree decode with prefix reuse (`runEagleTargetTreeDecode`).
  - **[x]** Packed tree masks in attention (`spec_packed_mask` → `UnifiedAttentionLayer`).
  - **[x]** Tree logits → per‑node `target_tokens` (device argmax + scatter).

- Acceptance + multi‑token tails + KV rewind:
  - **[x]** Device tree acceptance (`invokeTreeAcceptByIdsWithPaths`, strict ID equality).
  - **[x]** Tail commit via `DynamicDecodeLayer::ForwardMultiStep`
           (EOS, seq_limit_len / max_new_tokens, per‑slot finished).
  - **[x]** Multi‑token metrics + KV rewind driven by committed tail lengths.

- Eagle‑3 converter, geometry, capture + FC:
  - **[x]** Converter exports Eagle‑3 FC/QKV/WO/MLP/norms/embeddings/LM head
           with correct geometry into draft dir + `config.yaml`.
  - **[x]** `EagleModule::load` enforces Eagle‑3 geometry and builds
           `Eagle3DraftLayerWeight` with strict shape checks and local fallbacks.
  - **[x]** UnifiedDecoder capture width matches `eagle_fc_in_dim`; FC+norm path
           is enforced and locally disabled per engine on mismatch.

- Eagle‑3 draft layer under UnifiedDecoder:
  - **[x]** `Eagle3DraftLayerWeight` (attn + FFN + norms) built from converter exports.
  - **[x]** `Eagle3DraftLayer::Forward` path exists:
           RMSNorm → attention (UnifiedAttentionLayer when geometry OK,
           otherwise shallow QKV+V→Wo) → RMSNorm → GatedMLP →
           residual + output RMSNorm.
  - **[x]** `UnifiedDecoder::ForwardDraft` uses `Eagle3DraftLayer` when available.
  - **[x]** `LlamaV2::runEagle3DraftTreeDecode` drives draft logits and fills
           `EagleBuffers::inputs.draft_tokens/target_tokens`.
  - **[x]** For `spec_method == "eagle3"`, `dynamicDecodeWithSpecMulti` uses
           `runEagle3DraftTreeDecode` exclusively; EagleModule draft is used only
           for non‑Eagle‑3 modes.
  - **[ ]** Eagle‑3 draft attention still runs at “single‑position” semantics
           (q_len = kv_len = 1, no KV reuse) – multi‑position target‑tree parity
           with TensorRT‑LLM is still pending.

- SpecPV partial KV:
  - **[x]** `SpecPVCacheConfig` + `PartialKVCache` implemented (`specpv_kv_cache`).
  - **[x]** Seeding from full KV (`initSpecPVFromFullKV`) and partial/full
           switching policy in `LlamaV2`.
  - **[x]** Tree decode can run against partial KV in SpecPV mode.
  - **[x]** Post‑acceptance partial KV update wired to EAGLE committed tail
           lengths via `PartialKVCache::update_after_acceptance` and
           `LlamaV2::updateSpecPVAfterAcceptance`, with per‑layer/slot guards.

---

## 1. Eagle‑3 Draft Layer – Remaining Work

### 1.1 Tighten real multi‑head attention usage

**Where:**
- `src/turbomind/models/llama/EagleDraftLayer.{h,cc}`
- `src/turbomind/models/llama/unified_attention_layer.{h,cc}` / `LlamaAttentionLayer` (reference)

**Current:**
- `Eagle3DraftLayer::Forward` does:
  - `input_norm` RMSNorm on `input_hidden`.
  - If geometry is valid (hidden_dim == head_num * size_per_head) and
    `UnifiedAttentionLayer` is available:
    - Calls `UnifiedAttentionLayer::Forward` once with `q_len = kv_len = 1`.
  - Otherwise falls back to a shallow fused QKV+V→Wo path using
    `attn.qkv.weight` and `attn.output.weight`.
  - Then FFN + residual + output RMSNorm as a mini‑decoder block.

**TODO:**
- [ ] Ensure Eagle‑3 always uses UnifiedAttentionLayer when geometry allows:
  - Validate that `head_num`, `kv_head_num`, `size_per_head` are read from
    Eagle‑3 geometry and match GPT‑OSS‑120B config.
  - Confirm in logs (when `eagle_debug` is enabled) that UnifiedAttentionLayer
    is actually used in normal Eagle‑3 runs (not just falling back).
- [ ] For future multi‑position draft paths (if needed):
  - Extend `Eagle3DraftLayer::Forward` and/or a new `ForwardTree` to accept
    `q_len > 1` and `kv_len >= q_len`, using the same KV/rope path as
    the main decoder.
  - This is optional but required for strict TensorRT‑LLM parity.

**Guards:**
- [x] If attention cannot be set up (geometry mismatch, invalid head config):
  - Logs `[EAGLE3][Draft] invalid attention geometry; skipping Eagle3DraftLayer::Forward`.
  - Passes through `output_hidden = input_hidden`.
  - Does **not** modify global EAGLE state.

### 1.2 Confirm Eagle‑3 draft source is solely `UnifiedDecoder::ForwardDraft`

**Where:**
- `src/turbomind/models/llama/LlamaV2.cc`
- `src/turbomind/models/llama/EagleModule.cc`

**Status:**
- [x] For `engine_param.spec_method == "eagle3"`:
  - `LlamaV2::dynamicDecodeWithSpecMulti` uses only:
    - `runEagle3DraftTreeDecode` → `UnifiedDecoder::ForwardDraft` → LM head →
      device Top‑K → `EagleBuffers::inputs.draft_tokens/target_tokens`.
  - `EagleModule::forward_draft_tree` is used only for legacy (non‑Eagle‑3) modes.

**TODO:**
- [ ] Keep this invariant when refactoring:
  - Any new Eagle‑3 draft implementation (e.g. multi‑position) must live under
    UnifiedDecoder and be invoked via `ForwardDraft` / `runEagle3DraftTreeDecode`.
  - `EagleModule` stays responsible only for non‑Eagle‑3 draft modes.

### 1.3 Eagle‑3 debug binding and HF/TRT comparison

**Where:**
- `src/turbomind/python/bind.cpp`
- `tests/turbomind/eagle3_compare.py`

**Status:**
- [x] `_turbomind.eagle_forward_logits_debug` / `_turbomind.eagle3_forward_debug`
  share a C++ helper that:
  - Imports `hidden_states` (and optionally `captured_hidden`) via DLPack.
  - If an Eagle‑3 draft layer is present:
    - Runs `Eagle3DraftLayer::Forward` + LM head directly.
    - Returns `logits` and, when enabled, stage‑wise intermediates
      (e.g. `attn_out`, `ffn_out`, `pre_head_hidden`).
  - Otherwise falls back to the legacy EagleModule shallow path.
- [x] `tests/turbomind/eagle3_compare.py` calls this debug binding and computes
  argmax/top‑k overlap for logits; some variants already print per‑stage stats.

**TODO:**
- [ ] Ensure `eagle3_compare.py` always uses the Eagle‑3 draft path:
  - Prefer `_turbomind.eagle3_forward_debug` and assert that it exercises
    `Eagle3DraftLayer` (not the legacy path).
- [ ] In `eagle3_compare.py`:
  - For each stage where HF and TM tensors exist:
    - ATTN_OUT, FFN_OUT, PRE_HEAD, LOGITS:
      - Compute `mean_abs_diff`, `max_abs_diff`, cosine similarity.
    - For LOGITS:
      - argmax match rate and top‑k overlap.
  - Use this as the core numeric loop for tuning Eagle‑3 draft geometry and
    capture ordering.

### 1.4 Iterate numerically until draft logits are usable

**Where:**
- `tests/turbomind/eagle3_compare.py`
- `TensorRT-LLM/` reference (`Eagle3DecoderLayer`, `Eagle3DraftModel`)

**TODO:**
- [ ] For GPT‑OSS‑120B‑Eagle3:
  - Compare TM vs HF stage‑wise and adjust only when metrics show clear issues:
    - capture layer indices/order vs HF,
    - QKV input composition (`[embed_norm, fc_norm]`, etc.),
    - norm placements (only if absolutely necessary).
- [ ] Stop when:
  - LOGITS `argmax_match_rate > 0` with non‑trivial top‑k overlap, and
  - LOGITS cosine similarity is reasonable given MXFP4/BF16 vs HF.

### 1.5 Final Eagle‑3 draft cleanup

**TODO:**
- [ ] Once the new Eagle‑3 draft layer is stable:
  - Remove any remaining Eagle‑3‑specific shallow QKV+Wo draft paths and
    debug‑only code in `EagleModule`.
  - Verify:
    - All draft tokens for `spec_method == "eagle3"` come from
      `UnifiedDecoder::ForwardDraft` + LM head + Top‑K.
    - `EagleModule` does not participate in Eagle‑3 drafting at all.

---

## 2. SpecPV Partial KV – Remaining Work

### 2.1 Explicit post‑acceptance update in `PartialKVCache`

**Where:**
- `src/turbomind/models/llama/specpv_kv_cache.{h,cc}`

**Status:**
- [x] `SpecPVCacheConfig` and `PartialKVCache` exist, with:
  - K/V segments (sink, retrieval, window, buffer),
  - summary Kmax/Kmin, retrieval scoring, update/refresh/reset.
- [x] `PartialKVCache::update_after_acceptance(layer_idx, slot, advance_tokens)`
  is implemented and used to advance `verified_lens_[layer_idx]` and update
  `global_verified_len_`.
  - On invalid `layer_idx`, zero `buffer_size()`, negative current length,
    or buffer overflow:
    - Logs `[SpecPV][fallback] ...`.
    - Disables SpecPV for the engine (`enabled_ = false`) and resets
      `global_verified_len_` to 0.

### 2.2 Wire `update_after_acceptance` into the EAGLE multi‑token path

**Where:**
- `src/turbomind/models/llama/LlamaV2.cc`
- `src/turbomind/layers/DynamicDecodeLayer.cc` (for `committed_lengths`)

**Status:**
- [x] After `dynamicDecodeWithSpecMulti` commits tails, `LlamaV2`
  calls `updateSpecPVAfterAcceptance`, which:
  - Reads per‑slot committed tail lengths from `ForwardMultiStep`.
  - Treats single‑token steps as `advance = 1`.
  - For each slot and each layer, calls
    `specpv_kv_cache_->update_after_acceptance(layer, slot, advance)`
    when SpecPV is enabled.
  - If the cache disables itself during these updates, logs
    `[SpecPV][fallback] PartialKVCache update_after_acceptance failed; disabling SpecPV for this engine.`
    and clears SpecPV state without affecting EAGLE or baseline KV.

### 2.3 Keep partial/full switching disciplined

**Where:**
- `LlamaV2` SpecPV helpers (`isSpecPVEnabled`, `shouldUseSpecPV`,
  `initSpecPVFromFullKV`, refresh logic)

**Status / remaining checks:**
- [x] `shouldUseSpecPV`, `specpv_partial_steps_`, and headroom thresholds:
  - Gate entry into SpecPV based on sequence length.
  - Force full‑KV tree decode when partial steps or buffer headroom are
    exhausted.
  - Reseed the partial KV from full KV via `initSpecPVFromFullKV`,
    then rely on `update_after_acceptance` for buffer‑local tails.
- [ ] When tuning SpecPV further, always verify that:
  - EAGLE semantics (tree structure, acceptance, EOS/stop handling) are
    unchanged.
  - SpecPV only affects which KV entries the target attends to during
    target‑tree decode, not the logical sequence of accepted tokens.

---

## 3. Quick Numeric/Perf Checklist Before Calling It “Done”

Once the TODOs above are implemented, the final validation loop should be:

- [ ] `tests/turbomind/eagle3_compare.py`:
  - Stage stats for Eagle‑3 draft:
    - ATTN_OUT, FFN_OUT, PRE_HEAD, LOGITS vs HF Eagle‑3.
  - LOGITS:
    - `argmax_match_rate` and top‑k overlap > 0.

- [ ] `inference/benchmark_speculative.py` / `run_spec_suite.sh`:
  - For GPT‑OSS‑120B + Eagle‑3 draft:
    - `mean_acceptance_length > 1`.
    - `fraction_steps_accept_ge2 > 0`.
    - Throughput ≥ baseline (non‑speculative) in key scenarios (e.g., 8K/32K).

- [ ] SpecPV‑enabled runs (long context only):
  - EAGLE acceptance stats similar to full‑KV runs.
  - Lower target‑tree decode cost at long context (fewer KV tokens per step).

At that point, TurboMind’s Eagle‑3 speculative decoding is structurally and
numerically aligned as far as is reasonable with TensorRT‑LLM, with SpecPV
providing an additional, optional verification optimisation on top.

