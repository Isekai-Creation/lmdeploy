{
  "latency_ms_per_token": {
    "mean": 5.5985051509752,
    "min": 5.5985051509752,
    "max": 5.5985051509752,
    "values": [
      5.5985051509752
    ]
  },
  "throughput_tokens_per_sec": {
    "mean": 178.61910867864626,
    "min": 178.61910867864626,
    "max": 178.61910867864626,
    "values": [
      178.61910867864626
    ]
  },
  "memory_gb": {
    "mean": 0.0,
    "max": 0.0,
    "utilization_pct": 0.0
  },
  "total_runs": 1,
  "eagle_speculation": {
    "num_drafts": 483,
    "total_draft_tokens": 2415,
    "total_accepted_tokens": 1341,
    "mean_acceptance_rate": 0.55527950310559,
    "mean_acceptance_length": 3.7763975155279503,
    "num_spec_tokens": 5,
    "mean_accepted_tokens_per_draft": 2.7763975155279503,
    "mean_tokens_per_seq": 5.0,
    "max_tokens_per_seq": 5,
    "max_acceptance_length": 4,
    "fraction_steps_accept_ge2": 0.6935817805383023,
    "mean_committed_extras": 2.080745341614907,
    "enabled": true
  },
  "scenario": {
    "name": "Speculative_Single_Context8K_5tokens",
    "batch_size": 1,
    "context_length": 8192,
    "max_new_tokens": 8192,
    "use_speculation": true,
    "num_spec_tokens": 5,
    "perf_mode": false,
    "micro_run": true
  },
  "system": {
    "gpu_name": "NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition",
    "gpu_memory_total_gb": 101.958877184,
    "timestamp": "2025-12-15T16:04:31.780072",
    "turbomind_build_id": "eagle3-align-debug-v1"
  }
}