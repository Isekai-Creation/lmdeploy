# TurboMind EAGLE3 – Remaining Coding Tasks for TensorRT‑LLM‑Style Multi‑Token Speculative Decoding

This file lists **only implementation / wiring tasks** still required for
TurboMind’s multi‑token EAGLE/EAGLE3 to behave like TensorRT‑LLM. There are
no test or documentation items here.

Statuses:
- `[ ]` pending / not implemented yet

---

## 1. Target‑Tree Decode & Target Verification (core C++/CUDA)

These tasks make the target model actually verify the EAGLE tree, not just
the next token. They are the main blockers for TensorRT‑LLM parity.

### 1.1 Base‑model target‑tree decode

- [x] **[A] Add explicit tree‑decode entry point**
  - Introduce a `runEagleTargetTreeDecode(int batch_size)` (or similarly
    named) method on `LlamaV2` that:
    - Assumes `EagleBuffers::inputs.eagle_net_input_ids`,
      `.eagle_net_position_ids`, `.eagle_net_hidden_indices`,
      `.eagle_net_gen_lens` are already filled by `targetTreeDecode()`.
    - Executes a dedicated tree decode pass and leaves logits / IDs in
      EAGLE buffers for acceptance.
  - Call this from `LlamaBatch::Forward` / `LlamaV2_eagle::eagleSpeculativeStep`
    after tree + masks + `targetTreeDecode()` and before calling the
    acceptance kernel.

- [x] **[B] Implement scratch‑KV tree decode pass**
  - Reuse prefix KV from `SequenceManager` as read‑only:
    - Use the same `kv_block_ptrs_`, `cu_block_nums_`, and
      `sequence_lengths_` inputs as baseline decode.
  - Allocate a scratch KV region for tree tokens:
    - Either by reserving blocks per sequence in `BlockManager`, or by
      extending existing KV helpers with a “scratch blocks” table that is
      never attached to `Sequence::blocks`.
  - Drive `UnifiedDecoder` on the flattened tree tokens:
    - Use `eagle_net_input_ids` / `eagle_net_position_ids` instead of
      `input_ids_buf_`.
    - Use `eagle_net_gen_lens` and `sequence_lengths_` to build the
      equivalent of `h_input_length_buf_` / `h_context_length_buf_` for the
      tree pass.
  - Ensure all K/V writes during this pass go to the scratch KV blocks and
    are discarded after acceptance (no mutation of live `Sequence::blocks`).

- [x] **[C] Add tree‑decode logits buffer and call `postDecodeEmbedding`**
  - Extend `EagleBuffers` or `LlamaV2` to hold a dedicated logits buffer for
    tree tokens, e.g. `Tensor eagle_tree_logits` or a raw
    `[num_tree_tokens, vocab_size_padded]` buffer.
  - After the scratch tree decode `Forward`, call `LlamaV2::postDecodeEmbedding`
    with the tree hidden states to fill this logits buffer, just like the
    main decode path does for the current step.

### 1.2 Tree masks in attention

- [x] **[C] Integrate packed tree masks into `UnifiedAttentionLayer`**
  - Add optional arguments / state so that `UnifiedAttentionLayer` can
    consume a per‑token packed mask derived from
    `EagleBuffers::inputs.packed_masks` when running the tree decode pass.
  - For the tree decode path:
    - Ensure Q/K/V computation uses these masks so that tree nodes attend
      only to allowed ancestors / branches (similar to TRT‑LLM’s
      `eagleDecodingKernels` behaviour).
  - Keep the baseline decode path unchanged when no mask is provided.

### 1.3 Logits → per‑node `target_tokens`

- [x] **[B] Implement device‑side argmax → `target_tokens` scatter**
  - Given tree logits `[num_tree_tokens, vocab_size_padded]` and
    `eagle_net_hidden_indices` `[num_tree_tokens, 2]` (slot, token_idx):
    - Launch a kernel that:
      - Computes `argmax_vocabulary` per row,
      - Maps row index → `(slot, token_idx)`,
      - Writes the resulting ID into
        `EagleBuffers::inputs.target_tokens[slot * max_decoding_tokens + token_idx]`.
  - Keep layout and dtype consistent with
    `invokeTreeAcceptByIdsWithPaths` expectations (`int32` IDs, flattened
    `[max_batch_size, max_decoding_tokens]`).

### 1.4 Wire acceptance to real per‑node target IDs

- [x] **[A] Swap acceptance over to tree‑decoded `target_tokens`**
  - Update `LlamaV2::eagleSpeculativeStep` so that, when
    `enable_eagle_target_tree == true`:
    - It assumes `inputs.target_tokens` has been filled by the tree decode
      argmax path (not by host‑fabricated next‑step IDs).
    - It calls `invokeTreeAcceptByIdsWithPaths` using:
      - `draft_ids  = inputs.draft_tokens`,
      - `target_ids = inputs.target_tokens`,
      - `paths      = inputs.draft_paths`,
      - `batch_slots` as currently wired.
  - Keep the old host‑fabricated `target_tokens` path as a fallback when
    tree decode fails a runtime check or is disabled.

### 1.5 BF16 / MXFP4 correctness for tree decode

- [x] **[C] Enforce BF16 compute and MXFP4 weight usage**
  - Ensure the tree decode path:
    - Uses BF16 activations (matching GPT‑OSS compute) and MXFP4 weights for
      GPT‑OSS‑120B just like the baseline decode path.
    - Allocates the tree logits buffer with a float type appropriate for
      stable argmax (e.g. FP32).
  - Audit dtype usage in:
    - Tree hidden‑state buffers passed into `postDecodeEmbedding`,
    - Tree logits → `target_tokens` scatter kernel,
    - Any new scratch KV structures introduced for tree decode.

---

## 2. Multi‑Token Engine & DynamicDecode Parity

These tasks close behavioural gaps between multi‑token EAGLE3 and baseline
`DynamicDecode` semantics so that multi‑token steps are “first‑class citizens”
instead of bolted‑on.

- [x] **[B] Finalize integration with `DynamicDecodeLayer`**
  - Current state:
    - `LlamaV2::dynamicDecodeWithSpec` is wired and receives `decoder_features`
      and a populated `SpecContext` (per‑slot sequences, device sequence
      lengths, planned draft tokens, EAGLE flags).
    - It still delegates all speculative work to the existing EAGLE glue in
      `LlamaBatch::Forward` / `LlamaV2_eagle::eagleSpeculativeStep`; EAGLE
      draft, tree decode, acceptance, multi‑token commit, and KV rewind all
      happen outside `dynamicDecodeWithSpec`.
  - Final integration strategy (to be implemented in a later iteration):
    - Keep `DynamicDecodeLayer` as the single‑token base decode.
    - Use `dynamicDecodeWithSpec` only to fuse *target‑tree decode* and
      *acceptance* around that base step:
        - Run `dynamicDecode(...)` for the base token.
        - Inside `dynamicDecodeWithSpec`, use `decoder_features`,
          `SpecContext` and existing helpers to:
            - run EAGLE draft + target‑tree decode on device,
            - call `invokeTreeAcceptByIdsWithPaths`,
            - expose per‑step acceptance results to `LlamaBatch`.
    - Leave multi‑token append (`advanceSequencesByEagleAcceptance`) and KV
      rewind (`runEagleKVRewind`) in `LlamaBatch`, which already has access
      to `Request` / EOS / `max_new_tokens` state.
  - Ensure that in multi‑token EAGLE mode:
    - `output_ids`, `finished`, `sequence_length` seen by callers reflect
      the accepted tokens (base + extras), not just the first token.

- [x] **[A] Clean up multi‑token advancement and `g.step` handling**
  - Tighten `advanceSequencesByEagleAcceptance` and
    `runEagleMultiTokenAdvance` so that:
    - The step counter `g.step` and the time axis in `token_ids_buf_` are
      updated consistently for multi‑token steps.
    - No sequence can get out of sync between:
      - The committed dynamic token for the step, and
      - The extra tokens appended via EAGLE acceptance.

- [x] **[C] Align EOS / stop / `max_new_tokens` semantics**
  - Refine the logic in multi‑token advancement and per‑slot kill switches
    so that:
    - EOS is never “skipped over” by extra accepted tokens.
    - Per‑request stop conditions (EOS, `max_new_tokens`, other stop
      criteria) match baseline behaviour even when multiple tokens are
      accepted in one step.
  - Keep the implementation conceptually aligned with TensorRT‑LLM’s
    `EagleDecodingLayer` stop/accept logic wherever possible.

---

## 3. Performance, Parallelism, and Clean‑up

These tasks are not strictly required for correctness but are important for
making the implementation practical and robust in production.

- [x] **[B] Reduce host↔device copies in EAGLE paths**
  - Identify and remove avoidable host/device memcpy in:
    - Draft sampling (`draft_logits` / `eagle_sampling_logits`),
    - Tree construction and acceptance,
    - Target‑tree decode (logits and `target_tokens`).
  - Move as much sampling / argmax / acceptance work as possible to device
    kernels, keeping host involvement minimal.

- [x] **[C] Make multi‑token EAGLE behaviour explicit under TP/DP/PP**
  - Decide how multi‑token EAGLE should behave when:
    - `tp_size_ > 1`,
    - Data or pipeline parallelism is enabled.
  - Implement one of:
    - A fully correct multi‑token path under these topologies (mirroring
      the single‑GPU behaviour), or
    - A clear, early runtime gate that disables multi‑token EAGLE and
      logs a reason when TP/DP/PP are active.

---

## 4. DynamicDecode Multi‑Position Parity (Advanced TRT‑LLM Alignment)

These items push TurboMind toward **full DynamicDecode‑level parity** with
TensorRT‑LLM’s EAGLE‑3 implementation. They assume sections 1–3 are already
functionally complete.

### 4.1 Tail semantics inside `DynamicDecodeLayer::ForwardMultiStep`

- [x] **[B] Apply full stop criteria to tail tokens**
  - Extend `ForwardMultiStep` so that each committed tail token is checked
    with the same logic as the base token:
    - EOS / multiple `eos_ids`,
    - stop‑words / bad‑words,
      - `max_new_tokens` / per‑slot length limits,
      - guidance / repetition‑penalty related state if present.
  - When a tail token triggers EOS/stop for a slot:
    - Mark that slot as finished,
    - Stop committing further tail tokens for that slot.

- [x] **[B] Drive KV/metrics strictly from committed tail lengths**
  - Use `ForcedTailContext::committed_lengths[i]` as the *only* source of
    truth for how many extras were actually written for slot `i`.
  - Ensure `updateEagleMetricsAndKVLengths` and `runEagleKVRewind` derive
    `kv_draft_lengths` / `kv_accepted_lengths` and all EAGLE metrics from:
      - `1 + committed_lengths[i]` (base + committed extras),
    - not from planned lengths or raw accepted lens before tail clamping.

### 4.2 EAGLE3 draft head & numerics (EagleModule parity)

- [x] **[B] Remove remaining approximations in Eagle3 draft head**
  - Align `EagleModule`’s Eagle3 path with TensorRT‑LLM / HF Eagle3:
    - Q/K/V projection splits and shapes (e.g. `[4096,5760]`, `[512,5760]`),
    - `fc.weight` usage and hidden‑dim factors,
    - RMSNorm / activation order and any scaling factors.
  - Eliminate fallback behaviours (identity attention, zero value/WO) for
    the GPT‑OSS‑120B‑Eagle3 config so that its logits match the reference
    implementation up to numerical tolerance.

- [x] **[B] Wire strict Eagle3 geometry from converter into EagleModule**
  - Ensure `eagle_draft_converter.py` emits all geometry/config entries
    required by the tightened Eagle3 path (Q/K/V sizes, FC factors, layer
    counts), and `EagleModule` consumes them without defaulting to legacy
    EagleNet assumptions.

### 4.3 Final clean‑up for B (no scaffolding)

- [x] **[B] Remove dead EAGLE glue and duplication**
  - Delete any unused EAGLE helper paths that were superseded by the fused
    `dynamicDecodeWithSpecMulti` + `ForwardMultiStep` implementation, so
    there is a single source of truth for:
      - draft sampling,
      - tree decode and acceptance,
    - multi‑token commit.

---

## 5. SpecPV‑Style Partial Verification for EAGLE3 (Next Phase)

These items describe a *new* optimisation layer on top of the fully
implemented EAGLE3 + target‑tree decode path. They are **not required**
for TensorRT‑LLM parity, but aim to bring SpecPV’s partial KV technique
into TurboMind for long‑context EAGLE3 runs.

### 5.1 Engine configuration and gating

- [x] **[A] Add SpecPV flags to EngineParam and Triton config**
  - Extend `EngineParam` (`llama_params.h`) with:
    - `bool enable_specpv{false};`
    - `int  specpv_block_size{16};`
    - `int  specpv_n_sink_blocks{2};`
    - `int  specpv_n_retrieval_blocks{256};`
    - `int  specpv_n_window_blocks{8};`
    - `int  specpv_n_spec_tokens_buf{128};`
    - `int  specpv_partial_threshold{4096};`
    - `int  specpv_full_refresh_steps{32};`
  - Parse these from Triton YAML / LMDeploy `SpeculativeConfig` in
    `LlamaTritonModel` / async_engine, mirroring the existing
    `enable_eagle_target_tree` wiring.

- [x] **[A] Add SpecPV gating helpers to LlamaV2**
  - Implement:
    - `bool isSpecPVEnabled() const;`
    - `bool shouldUseSpecPV(int seq_len) const;`
  - `isSpecPVEnabled()` should check `engine_param_.enable_specpv` and a
    `specpv_supported_` flag (e.g. TP/DP/PP constraints).
  - `shouldUseSpecPV(seq_len)` should mirror SpecPV’s `should_partial_verify`
    by requiring:
    - context length above `specpv_partial_threshold`,
    - a live partial KV cache object,
    - and enough KV budget for `eagleMaxEngineTokensPerStep() + 1` tokens.

### 5.2 PartialKVCache core (TurboMind analogue of SpecPV)

- [ ] **[B] Implement SpecPVCacheConfig and PartialKVCache**
  - `SpecPVCacheConfig`:
    - Holds `block_size`, `n_sink_blocks`, `n_retrieval_blocks`,
      `n_window_blocks`, `n_spec_tokens_buf`.
    - Provides helpers:
      - `int sink_size() const;`
      - `int retrieval_size() const;`
      - `int window_size() const;`
      - `int total_budget() const;  // sink+retrieval+window+buffer`
  - `PartialKVCache`:
    - Owns per‑layer KV tensors: `[max_batch, num_kv_heads, total_budget, head_dim]`
      and slices `"sink"`, `"retrieval"`, `"window"`, `"buffer"` in token order.
    - Maintains per‑layer:
      - `summary_key_states` (Kmax/Kmin for blocks beyond sink),
      - `summary_block_count`,
      - `verified_lens[layer]`,
      - and a global `global_verified_lens`.
    - Methods:
      - `summary_key_states(layer_idx, key_states, seq_len)` – compute Kmax/Kmin
        for new blocks (Eq. (1) in SpecPV).
      - `refresh_retrieval(layer_idx, query_states, key_states, value_states, seq_len)` –
        block scoring and top‑K selection (Eq. (2),(3)); fill retrieval/window
        slices.
      - `update(layer_idx, new_keys, new_values)` – append newly verified tokens
        into the buffer slice and return active [sink+retrieval+window+buffer]
        KV views.
      - `init_from_full_kv(...)` – seed sink/retrieval/window from full KV once.
      - `reset()` / `reset_buffer()`.
  - Implementation status:
    - `SpecPVCacheConfig` and `PartialKVCache` now exist in `specpv_kv_cache.{h,cc}` and are wired into `LlamaV2` construction and SpecPV
      gating:
      - Per-layer KV buffers `[max_batch, num_kv_heads, total_budget, head_dim]` are allocated on device for both keys and values.
      - Segment views (`sink`, `retrieval`, `window`, `buffer`) are implemented for K and V.
      - `summary_key_states` computes real Kmax/Kmin block summaries (float32) on host; `refresh_retrieval` uses those summaries to select
        top blocks and fills retrieval/window K/V slices from full KV; `update` writes new K/V into the buffer and returns active
        `[sink+retrieval+window+buffer]` views; `reset_buffer` clears buffer K/V and resets verified lengths.
    - What remains at this level is seeding from the full TurboMind KV cache (`init_from_full_kv` behaviour), which is handled by
      `LlamaV2::initSpecPVFromFullKV` in Section 5.3; until that wiring is complete, partial KV is not yet populated from live prefix KV
      and tree decode still uses the full‑KV layout.

- [ ] **[B] Attach PartialKVCache to LlamaV2**
  - Add a `SpecPVCacheConfig specpv_cache_config_` and
    `std::unique_ptr<PartialKVCache> specpv_kv_cache_` to `LlamaV2`.
  - Initialize them from `EngineParam` in the LlamaV2 constructor when
    `enable_specpv` is true and geometry is compatible.

### 5.3 SpecPV‑mode target‑tree decode

- [ ] **[B] Add SpecPV mode to runEagleTargetTreeDecode**
  - Extend `LlamaV2::runEagleTargetTreeDecode` with a SpecPV branch:
    - Full‑KV mode (today’s behaviour) stays as the default when
      `!shouldUseSpecPV(seq_len)` or SpecPV is disabled.
    - SpecPV mode:
      - Uses `PartialKVCache` to construct the base KV for the target
        tree decode:
        - sink slice → earliest tokens (anchor),
        - retrieval slice → top‑scoring blocks,
        - window slice → most recent tokens,
        - buffer slice → space to append tree tokens’ KV.
      - Appends tree tokens’ K/V into the buffer via
        `PartialKVCache::update(...)`.
      - Runs `UnifiedDecoder::Forward` over this partial KV view instead
        of a full‑prefix scratch KV:
        - Build `h_prefix_blocks` / `h_extra_blocks` for the partial
          prefix and tree tokens only,
        - Construct `kv_block_ptrs` over SpecPV’s active K/V region
          (sink+retrieval+window+buffer_verified) plus tree scratch,
        - Set `h_k_len` for each slot to the partial prefix length plus
          `tree_len` instead of `prefix_len + tree_len` from full KV.
  - Keep tree masks (`spec_packed_mask`) and post‑decode logic
    (logits → target_tokens → acceptance) unchanged.
  - Implementation status:
    - `runEagleTargetTreeDecode` still uses the full‑KV scratch path for all modes; SpecPV currently only tracks verified lengths and step
      counters and does not yet alter the KV layout or attention cost.

- [ ] **[B] Seed SpecPV from a full‑KV tree step**
  - After the first full‑KV target‑tree decode at long context:
    - Call `LlamaV2::initSpecPVFromFullKV(committed_prefix_len)` to:
      - Flatten the full prefix KV cache per layer into contiguous
        `[B, H, L, D]` tensors (e.g. via an internal helper that reuses
        `invokeFlattenKV_v2`),
      - Call `PartialKVCache::summary_key_states` and
        `PartialKVCache::refresh_retrieval` for each layer to populate:
        - sink / retrieval / window K/V slices inside the partial cache,
      - Reset buffer usage (`reset_buffer`) and mark a
        `specpv_retrieval_initialized_` flag on `LlamaV2` so subsequent
        tree decodes can safely use the partial KV view.
  - Implementation status:
    - `LlamaV2::initSpecPVFromFullKV` and `updateSpecPVAfterAcceptance` currently keep `PartialKVCache`’s verified lengths in sync with
      committed sequence lengths after DynamicDecode+EAGLE acceptance, and `specpv_partial_steps_` / buffer capacity drive a simple
      full‑refresh reset.
    - Actual KV flattening from full KV into `[B,H,L,D]`, and
      retrieval/window population inside `PartialKVCache`, remain TODO;
      until these are implemented, SpecPV is length/bookkeeping only and
      the tree decode path behaves identically to the full‑KV
      implementation.

### 5.4 Partial/full switching and refresh

- [ ] **[A] Implement SpecPV partial/full switching policy**
  - Inside `LlamaBatch::Forward` / `LlamaV2`:
    - Use `shouldUseSpecPV(seq_len)` to decide:
      - Full‑KV tree decode (default) vs SpecPV mode for this step.
    - Track:
      - A per‑engine partial‑step counter.
      - A per‑engine “buffer usage” indicator from `PartialKVCache`:
        `verified_lens[layer]` vs `n_spec_tokens_buf`.
  - Force full‑KV tree decode and partial cache refresh when:
    - The partial‑step counter exceeds `specpv_full_refresh_steps`, or
    - Buffer usage approaches `n_spec_tokens_buf`, or
    - Any KV invariant or geometry check fails for the SpecPV path.

- [ ] **[B] Update PartialKVCache after EAGLE acceptance**
  - After multi‑token acceptance and commit:
    - Use the committed EAGLE extras to:
      - Update `partial_kv_cache_->update(...)` per layer with the
        newly verified tokens (keys/values from TurboMind KV).
      - Increment `verified_lens[layer]` accordingly.
    - Keep `global_verified_lens` aligned with the full‑KV prefix as in
      SpecPV:
      - Only bump `global_verified_lens` on full‑KV refresh steps.

### 5.5 Interaction with existing KV and EAGLE paths

- [ ] **[C] Keep SpecPV orthogonal to EAGLE semantics**
  - Ensure SpecPV does not change:
    - EAGLE3 draft head maths or geometry.
    - Tree masks / structure.
    - `invokeTreeAcceptByIdsWithPaths` semantics (ID‑equality).
  - SpecPV should only affect:
    - Which KV entries the target attends to during tree decode.
    - How KV is updated and reused between partial/full verification
      steps.

- [ ] **[C] Maintain baseline and TRT‑LLM parity modes**
  - When `enable_specpv == false`:
    - Behaviour must remain identical to the now‑completed EAGLE3 /
      target‑tree implementation (Sections 1–4).
  - SpecPV mode should be easy to toggle at runtime via config so we can
    benchmark:
    - Full‑KV TurboMind EAGLE3 vs SpecPV‑enabled TurboMind EAGLE3.


---

## 5. Advanced: SpecPV‑Style Partial Verification on Top of EAGLE3 Target‑Tree Decode

This section sketches **future work**: integrating a SpecPV‑style *partial KV verification* path under the existing EAGLE3 target‑tree decode in TurboMind, to reduce verification cost for very long contexts. It is not required for TensorRT‑LLM parity, but it becomes relevant once 32K–64K contexts are common.

Reference implementation and paper:
- Code: `SpecPV/specpv/kv/kv_cache.py`, `specpv/speculate/{speculator.py,utils.py,configs.py}`, `specpv/models/modeling_llama_kv.py`.
- Paper: `SpecPV/PAPER.md`, especially §3.2 *Partial Verification*, §3.3 *Rectified with Full Verification*, Fig. 2, and Algorithm 1.

### 5.1 Conceptual overview

- **Problem:** At long context, even with EAGLE3 draft + target‑tree decode, verification dominates latency because attention always sees the full prefix KV.
- **SpecPV idea:** Maintain a *partial* target KV cache for verification consisting of:
  - **Sink tokens:** initial KV blocks kept always.
  - **Retrieval tokens:** blocks selected via block‑level summaries (`Kmax`, `Kmin`) and query similarity scores.
  - **Local window:** a fixed‑size tail of the most recent tokens.
  - **Spec buffer:** candidate / partially verified tokens awaiting correction.
- **Behaviour:**
  - For short context, verification uses full KV (no partial cache).
  - When context exceeds a partial KV budget:
    - Run one **full verification** step to initialize the partial KV.
    - Then run most steps in **partial verification** mode (tree decode attends only to partial KV + buffer).
    - Periodically perform full verification again to refresh the partial KV and clear accumulated errors.

### 5.2 Proposed engine‑level API and config

These are additive fields on top of existing speculative / EAGLE config; when disabled, behaviour is identical to today.

- Extend `EngineParam` (`src/turbomind/models/llama/llama_params.h`):
  - `bool enable_specpv{false};`
  - `int  specpv_block_size{16};`
  - `int  specpv_n_sink_blocks{2};`
  - `int  specpv_n_retrieval_blocks{256};`
  - `int  specpv_n_window_blocks{8};`
  - `int  specpv_n_spec_tokens_buf{128};`
  - `int  specpv_partial_threshold{4096};`  // context length above which partial KV can kick in
  - `int  specpv_full_refresh_steps{32};`   // max partial steps before a forced full verify

- Wire through Triton YAML `speculative_config` (alongside `enable_target_tree`), and through LMDeploy’s Python `SpeculativeConfig` object so users can enable SpecPV for EAGLE3 targets explicitly.

### 5.3 PartialKVCache data structure (C++ analogue of SpecPV)

Introduce a TurboMind‑side partial KV cache that mirrors SpecPV’s `PartialKVCache`:

- New `SpecPVCacheConfig`:
  - Fields: `block_size`, `n_sink_blocks`, `n_retrieval_blocks`, `n_window_blocks`, `n_spec_tokens_buf`.
  - Derived: `sink_size`, `retrieval_size`, `window_size`, `total_budget`.

- New `PartialKVCache` (C++ class, files `specpv_kv_cache.{h,cc}`):
  - For each layer:
    - Allocate `[max_batch_size, num_kv_heads, total_budget, head_dim]`.
    - Slice into:
      - `"sink"`   : first `sink_size` tokens,
      - `"retrieval"`: next `retrieval_size` tokens,
      - `"window"`: next `window_size` tokens,
      - `"buffer"`: final `n_spec_tokens_buf` tokens.
  - Maintain:
    - `key_states_summary[layer]["max"/"min"]` for block summaries, shape `[B, H, max_blocks, D]`.
    - `summary_block_count[layer]` (how many blocks have summaries).
    - `verified_lens[layer]` (how many tokens in buffer are now fully verified).
    - `global_verified_lens` (length of the fully verified prefix over which retrieval is defined).
  - Methods (1:1 with SpecPV):
    - `summary_key_states(layer_idx, key_states, seq_len)`:
      - Implements Eq. (1) of the paper (per‑block `Kmax`, `Kmin`).
    - `refresh_retrieval(layer_idx, query_states, key_states, value_states, seq_len)`:
      - Implements Eq. (2),(3) and `refresh_retrieval` in `kv_cache.py`:
        - Compute similarity scores vs summaries for each block,
        - Select top‑`n_retrieval_blocks`,
        - Gather keys/values into `"retrieval"` slice,
        - Fill `"window"` with last `window_size` tokens.
    - `update(layer_idx, new_key_states, new_value_states)`:
      - Append KV for newly (partially) verified tokens into `"buffer"` and return the active `[sink+retrieval+window+buffer]` view.
    - `init_key_values(full_kv)`:
      - Seed `sink` (and optionally initial retrieval/window) from full KV once, like SpecPV’s `init_key_values`.
    - `get_seq_length(layer_idx)`, `reset()`, `reset_buffer()`.

`LlamaV2` should hold:
- `std::unique_ptr<PartialKVCache> specpv_kv_cache_;`
- `SpecPVCacheConfig specpv_cache_config_;`
- Flags: `bool specpv_supported_{false};`.

### 5.4 Gating and integration with `runEagleTargetTreeDecode`

With the data structure in place, EAGLE3 tree decode can choose between full vs partial KV:

- New helpers on `LlamaV2`:
  - `bool isSpecPVEnabled() const`:
    - `return engine_param_.enable_specpv && specpv_supported_ && specpv_kv_cache_ != nullptr;`
  - `bool shouldUseSpecPV(int sequence_len) const`:
    - Mirrors SpecPV’s `should_partial_verify`:
      - `isSpecPVEnabled()`,
      - `sequence_len > specpv_partial_threshold`,
      - `specpv_kv_cache_->enabled && specpv_kv_cache_->retrieval_initialized`,
      - `specpv_kv_cache_->get_seq_length() + eagle_max_engine_tokens_per_step_ + 1 <= specpv_cache_config_.total_budget()`.

- In `LlamaV2::runEagleTargetTreeDecode`:
  - Full‑KV mode (**current behaviour**):
    - When `!shouldUseSpecPV(sequence_len)`:
      - Build scratch KV from full prefix blocks and run `UnifiedDecoder::Forward` as today.
  - SpecPV mode (**partial KV**):
    - When `shouldUseSpecPV(sequence_len)`:
      - Use `specpv_kv_cache_` as the base KV view:
        - `sink` + `retrieval` + `window` slices define the “trusted” prefix.
      - Append KV for tree tokens into `"buffer"` via `PartialKVCache::update`.
      - Run `UnifiedDecoder::Forward` with that composite KV instead of full prefix.

Tree masks, tree logits → `target_tokens`, and acceptance remain unchanged: SpecPV only narrows which KV positions the target attends to during tree decode.

### 5.5 Maintaining `global_verified_lens` / `verified_lens` and periodic full refresh

The bookkeeping should follow SpecPV’s `global_verified_lens` and per‑layer `verified_lens` semantics:

- **Full‑KV steps (initialization or refresh):**
  - After a tree decode step that used full KV:
    - Set `specpv_kv_cache_->global_verified_lens = current_sequence_len` for each active sequence.
    - Call `initSpecPVFromFullKV` (helper on `LlamaV2`) to seed `sink` / `retrieval` / `window` from the live full KV.
    - Reset `verified_lens[layer]` and buffer.

- **Partial‑KV steps:**
  - After `invokeTreeAcceptByIdsWithPaths` and `advanceSequencesByEagleAcceptance`:
    - Determine how many **extra tokens** were actually committed for each sequence.
    - Append their KV into the partial `"buffer"` for each layer via `PartialKVCache::update`.
    - Increment `verified_lens[layer]` accordingly.
    - Leave `global_verified_lens` unchanged (it still points to the fully verified prefix before partial steps), mirroring SpecPV’s `tree_decoding` + `update_inference_inputs` separation.

- **Periodic full refresh:**
  - When any of the following holds:
    - `verified_lens[layer]` approaches `n_spec_tokens_buf` (buffer nearly full),
    - Number of consecutive partial steps reaches `specpv_full_refresh_steps`,
    - Or the effective `get_seq_length()` is too close to `total_budget`.
  - Run a full‑KV `runEagleTargetTreeDecode` step, then:
    - Rebuild partial KV from full KV (`initSpecPVFromFullKV`),
    - Reset buffer and `verified_lens` counters.

At all times:
- If any SpecPV invariant fails (dtype/layout mismatch, buffer too small for `eagle_max_engine_tokens_per_step_`, unexpected KV geometry), log a `[LlamaV2][SpecPV][fallback] ...` message, set `specpv_supported_ = false`, free `specpv_kv_cache_`, and continue with the current full‑KV EAGLE3 behaviour.
